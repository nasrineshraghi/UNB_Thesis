%%--------------------Chapter 3------------------------
% \documentclass[../UNBThesis2.tex]{subfiles}
\setlength{\parindent}{2em}
% \begin{document}
\chapter{Literature Review}

Indoor localization technologies have been a key enabler for advancing the usefulness of the Internet of Things in biomedical and health care applications. Many localization technologies have been explored for generating location data of people in indoor spaces, including WiFi, BLE beacons, RFID tags, visible light wave, and ultra-wideband \cite{namiot2015indoor, jeon2018ble}. 

In particular, infra-red, optical (e.g., RGB videos or flat images), break beam, thermal, and ultrasonic sensors have been used for counting people in indoor spaces \cite{mautz2012indoor}. One simple way of counting people is using ultra-wideband radar sensors mounted in e-counter devices that can be used for counting multiple people passing through a passage or a wide door. Two sensors equipped with antennas which have narrow beam width are used to form two invisible electronic layers in the path. These layers are used for sensing the presence of a person and recognizing the direction of the movement.  E-counters are usually deployed at stairs and the entrances of indoor spaces. 

With the increasing proliferation of wireless LAN, WiFi signal strength measurements from access points have been used for localization. RSSI (Received Signal Strength Indicator) is a measurement of how well a mobile device can receive a signal from an access point or router. The IEEE 802.11 standard specifies that RSSI can be on a scale of 0 to up to 255 and that each chipset manufacturer can define their own “RSSI Max” value. Cisco, for example, uses a 0-100 scale, while Atheros uses 0-60. Vendors and chipset makers provide their own accuracy, granularity, and range for the actual power (measured as milliwatts or decibels) and their range of RSSI values (from 0 to RSSI maximum). 

Previous research work applied the AP partitioning-based method for improving indoor fingerprinting using WiFi RSS data \cite{hu2015improving, subedi2019improving}. They have also been successful applied for improving routing schemes for multi-level heterogeneous Wireless Sensor Networks, saving energy consumption \cite{wang2019affinity}. In this thesis, we are actually interested in clustering WiFi location data. The underlying assumption is that for each location of a mobile device in an indoor space, the WiFi RSS signals of these mobile devices are different. By relying on the variation of these signals in a distinct indoor space, the current location of a mobile device can be obtained.

The stream data points generated from e-counters and WiFi localization systems require streaming clustering since they are a sequence of potentially infinite, non-stationary data (the probability distribution of the unknown data generation process may change over time) arriving continuously (which requires an online phase through the data) where random access to the data is not feasible and storing all the arriving data is impractical (which requires an offline phase). To  the  best  of  our  knowledge,  streaming AP algorithms have  not  yet  been  applied for clustering e-counters and WiFi location data generated in indoor spaces. 




%The Affinity Propagation (AP) method for stream processing has been proposed to handle the recent past of data streams by applying the sliding time window. The data streams are partitioned into a sequence of time windows and then micro-clusters are continuously being generated for each time window. However, the AP model was originally designed for images of face, therefore, it requires to be adapted to incorporate an online phase for finding micro-clusters. 



%Data stream affinity propagation algorithm has been chosen for indoor localization data in this research work. For this algorithm, every data point is a centroid, and it means they have equal importance and there is no prior reason. Also, the AP algorithm does not require the number of clusters as an input which makes our work more robust, especially if it uses for the cloud side. AP's main issue is the computation efficiency that we make it possible by applying the time window model and making it a stream approach. This algorithm is applied in many scientific research and different datasets such as intrusion detection, energy, gene expression, psychology, business, physical science, social science, etc. However, to the best of our knowledge AP model has not yet been applied for any people counting data ,and streaming AP has been never used for any indoor localization dataset.

Overall, there are a few robust streaming algorithms based on the AP method. The clustering process requires a strategy capable of partitioning stream data points continuously while taking into account restrictions of memory and time. Table \ref{APCLU} summarizes the main characteristics of four streaming algorithms that were proposed in previous research works. 



\begin{table}[!ht]
\caption{Overview of streaming AP clustering algorithms }
\label{APCLU}
\begin{tabular}{lcccc}
\hline 
\textbf{Algorithms} & \multicolumn{1}{l}{\textbf{Year}} & \multicolumn{1}{l}{\textbf{Method}} & \multicolumn{1}{l}{\textbf{Processing}} & \multicolumn{1}{l}{\textbf{Time window model}}                               \\ \hline\midrule
StrAP               & 2008                              & AP                                  & Single-pass                             & Sliding                                                                      \\ \hline
IStrAP              & 2012                        & AP                                  & Single-pass                             & Sliding                                                                      \\ \hline
ISTRAP               &   2018        &    AP             &   Single-pass           & Sliding \\ \hline

APDenStream         & 2013                              & AP                                  & Online-offline                          & \begin{tabular}[c]{@{}c@{}}Sliding (online)\\ Pyramidal (offline)\end{tabular} \\ \hline\midrule
     %           &   2015        &    AP             &     Single-pass         &   Damped    \\
    %\hline
    %  SED-Stream-AP        &   2018        &    AP             &    Online-offline   & Damped(offline)\\
    % \hline
    % IStrAP               &   2018        &    AP             &   Single-pass           & - \\

\end{tabular}
\end{table}


%To control which part of data is going to be processed, time window models have been proposed.
%New ideas continue evolving in data streams over time. Evolving needs updating data stream algorithms to adjust to the changes such as handle well rapid cluster evolution patterns.
%To handle and generate data in the stream mode, open-source frameworks for IoT data stream are being developed including MOA \cite{holmes2007moa}, Scikit-multiflow \cite{montiel2018scikit}, streamDM C++ \cite{bifet2017extremely} and Apache SAMOA \cite{de2013samoa}. THIS SHOULD BE MOVED TO LR

% K-medoids algorithm \cite{macqueen1967some} is a good strategy to find clusters easy and fast by randomly choosing K initial exemplars from data and assign closest data points to these exemplar as shown in figure \ref{medo}, these exemplar can be purify in the next steps. The only thing should be consider is the number of exemplars are not changeable but the algorithm maximize the size of similarities between exemplars and other objects. k-medoids algorithm requires to be run with a various random initialization to find a suitable exemplar but this works well when clusters are small.  
% \begin{figure}
% \centering
% \includegraphics[width = 11cm,height = 7cm]{image/Chapters/Chapter2/3.png}
% \caption{K-medoids greedy solution for toy dataset}
% \label{medo}%\cite{dueck2009affinity}
% \end{figure}




%\section{Previous Research Work on Streaming AP }
 
%Due to the reason above, some research has been done on AP streaming clustering and introduce new approaches.

%Elmi
% It must be emphasized that both Divide-and-Conquer and two-level schemes keep their computational load
% within reasonable limits as they only build the data model upon the users explicit request. In the rest of time, they only maintain a summary of the data, which makes them ill-suited to applications such as system monitoring where the data model has to be continuously available at all times.


%There are a few algorithms are introduced based on AP algorithm for data stream clustering and they are shown 

% The other improvement of AP to handle huge datasets was WAP or weighted AP \cite{zhang2009toward}. Under the premise of not changing the amount of passed information, this algorithm integrates the neighboring points, making the integrated points have the same clustering results with the original points.
% , zhang2013data
%\todo[inline]{TO DESCRIBE THE ALGORITHMS

% - WORKFLOW = MODEL ->>> SINGLE-PASS WORKS, AND VERY IMPORTANT IS HOW THE STEPS WORK ON ONLINE/OFFLINE 
% - data input : labeled or not labeled data
% - strategies used for updating the clusters: decay function, updated thresholds???

% - evaluation criteria (and compare with what we are using to evaluate the quality of the clusters and the performance of the algoritm}

Overall, these streaming AP algorithms usually suffer from a quadratic computational complexity in the number $N$ of items. The time complexity of AP is $O(n^2*T)$, where $n$ is the number of samples and $T$ is the number of iterations until convergence happens\cite{refianti2017time}. This computational performance might become an issue for computing macro-clusters using large volumes of people counting data. It is important to develop strategies to improve the performance of AP models.

\vspace{7mm}
\hspace{-1 cm}
\textbf{StrAP Algorithm}

StrAP was the first algorithm proposed to extend affinity propagation for streaming data and was inspired by the DenStream algorithm \cite{zhang2008data}. It has a simple evolutionary workflow as illustrated in Figure \ref{stmodl} where a set of 4-tuples $(c_i,n_i,\sum{_i},t{_i})$ is represented, where  $c_i$ ranges over the clusters, $n_i$ is the number of data points associated to cluster $c_i$, $\sum{_i}$ is the distortion of $c_i$ $(\sum{d(x,c_i)^2})$, where $x$ ranges over all data points associated to $c_i$, and $t_i$ is the last timestamp when a data point was associated to $c_i$.

%\todo[inline]{ it is important to describe how the tupes look like as StrAP was described above}

\begin{figure}[!ht]
\centering
\includegraphics[width = 13 cm]{image/Chapters/Chapter3/strapmodel.PNG}
\caption{The workflow developed for the StrAP algorithm }
\label{stmodl}
\end{figure}


The number of clusters to be found is not pre-determined, and the clustering problem is defined in terms of energy minimization. An initial number of actual data points are selected as exemplar cluster-centroids, and the algorithm computes the cost of adding another new cluster-centroid. The penalty parameter value controls the cost of adding another exemplar. If the current data point does not fit the model according to its penalty value, it is automatically moved to a reservoir. A statistical test enables StrAP to catch drifting exemplars that significantly deviate away from the existing clusters. StrAP involves four main steps described as below:  

% The StrAP algorithm, as an online version of AP, proceeds by incrementally updating the current model if the current data point fits the model, and putting it in a reservoir otherwise. 
 



%The first step is weighted AP to handle duplicated objects without losing performance.
%Second, hierarchical WAP, dealing with quadratic AP complexity and reduce it by utilizing AP on subsets of data and then utilizing Weighted AP on the exemplars obtained from subsets.

%Eventually, with online clustering, STRAP extends Hierarchical WAP to deal with changes in the data distribution by updating exemplars and storing the outliers. As illustrated in Figure \ref{stmodl}, STRAP involves four main steps as follow: 


\begin{itemize}
    \item[$\bullet$] A first batch of data stream data points is selected and the first cluster-centroids are obtained using AP to initialize the StrAP algorithm.
    
    %AP is applied to the first set of selected data points to compute the first centroids and initialize the streaming AP model. THIS IS HOW YOUR MODEL WORKS!!!
    \item[$\bullet$] As new stream data points arrive,  each stream data point $x_t$ is compared to the existing centroids $e_i$. This comparison is carried out by computing the Euclidean distance of $x_t$, $e_i$ with the threshold $\epsilon$, which is a heuristically set, and the value is equal to the average distance between stream data points and centroids in the initial step. If $x_t$ is far from the nearest centroid, it goes to the reservoir. If not, $x_t$ is assigned to the $i^{th}$ cluster, and the clusters are updated accordingly. StrAP has a mechanism to forget old centroids which have not been visited for some time.
    
    \item[$\bullet$]  Two restart procedures have been proposed in StrAP. First, if the number of outliers in the reservoir exceeds the reservoir's size, the restart criterion is triggered. Second, the Page-Hinkley (PH) test is used for detecting an abrupt change in the average value of the data points in clusters. 
    
    \item[$\bullet$] If the restart criterion is satisfied either due to the reservoir filling up or if the PH test detects an abrupt change, the clusters are rebuilt by launching a weighted version of AP (WAP) using current centroids and the reservoir.
\end{itemize}

Previous research has explored the trade-off between the computational cost and the performance of StrAP. The distortion and purity metrics have been applied to evaluate the quality of the clustering results, using data sets such as the Intrusion Detection benchmark data (KDD99), synthetic stream data, and the streaming data from the EGEE grid system \cite{zhang2008data}.  

%\todo[inline]{Nasrin: check types of data used : labeled or not labeled}
Artificially generated data streams was used for testing the ability of StrAP in handling a dynamically changing data distribution \cite{zhang2008data}. The network connection data, KDD Cup 1999 (KDD99) Intrusion Detection was also used to evaluate the StrAP model for distinguishing between “bad” connections, called intrusions or attacks, and “good” normal connections. Each connection was labeled as one of 23 classes, the normal class and the specific kinds of attack. StrAP's clustering quality was tested with data streams containing EGEE jobs in the whole EGEE grid over 5 months. Besides the six attributes related to time-cost, each job was labeled by its final state, successfully finished (good job) or failed (bad job, including about 45 error types). The 5 million jobs include about 20 main error types (more than 1,500 occurrences). The job labels were used as an indicator of the clustering quality.

While the accuracy of StrAP was found satisfactory, the computational time was high, hampering its further use with large volumes of stream data.

% To validate a STRAP, the Intrusion Detection benchmark(KDD99) and EGEE real-world datasets are used for monitoring and discovering anomalies within a grid computing infrastructure. The result of this work is compared with DenStream, and comparatively satisfactory results are investigated. Also, computational time in this model is higher than DenStream. 

%\todo[inline]{from where have you taken the information below?? which paper?? WAS THIS A BENCHMARK}
%The proposed STRAP algorithm was analyzed on guaranteeing acceptable distortion loss when exemplars slightly drift from the already selected ones, with a small amount of memory and computing time. The performance of STRAP in clustering quality and efficiency is validated on the KDD’99 dataset and the URLs stream. However, STRAP improves clustering purity rather than DenStream, and computational time is also higher than the DenStream algorithm. In addition, STRAP is a model for the stream at any time, whereas DenStream only builds the model upon request. The validation on URLs stream also demonstrates that STRAP achieves very high accuracy and purity for collecting malicious URLs.




% % From APDENSTREAM:
% This algorithm can determine
% the number of clusters automatically and detect the real-time
% changes of the data stream at the same time. However, the
% clustering quality depends on the size of the sliding window.
% Meanwhile, it is not considering how the arrival time will
% affect the clustering results. The clustering effect is not
% satis factory when noises are too much



\vspace{7mm}
\hspace{-1 cm}
\textbf{IStrAP and ISTRAP Algorithms}

IStrAP introduced a simpler method to eliminate outliers as compared with the existing technique used in StrAP \cite{li2012improved}. An outlier here refers to an abnormal cluster that represents a behavior deviating from the normal clusters. The reservoir in StrAP emulates the sliding time window model, making clustering ineffective for handling outliers in the cached data. IStrAP relies on statistical analysis of the stream data points that are temporarily stored in the reservoir, removing outliers from the reservoir according to their statistical properties, and then clustering the remaining stream data points left in the reservoir. The process of removing outliers consists of four steps described as follows:

%This method is based on the statistical properties of the window data. The outlier refers to the abnormal behavior deviating from the normal value. Such data may be generated in emergency situations or generated when an error occurs. The process of removing outliers is consists of four steps. 



%to combine the current clusters  to re-cluster in a fast manner. Clustering is sometimes ineffective due to the handling of outliers well in the reservoir. To improve the efficiency of clustering results, they introduced a method to remove outliers. 
%This method is based on the statistical properties of the window data. The outlier refers to the abnormal behavior deviating from the normal value. Such data may be generated in emergency situations or generated when an error occurs. The process of removing outliers is consists of four steps. 

\begin{itemize}
    \item[$\bullet$]  Compute the reservoir's statistics such as maximum, minimum, sum, average, and standard deviation.
    \item[$\bullet$] Scan the reservoir to calculate the standard deviation of data points.
    \item[$\bullet$]  Set the standard deviation as the sampling parameter ($\sigma$) to reflect the distribution of the data in reservoir.
    \item[$\bullet$] Remove outliers if they are outside of the interval [Avg-$\sigma$, Avg + $\sigma$].
\end{itemize}

%\todo[inline]{what are the problems with IStrAP, and if it only used with labeled data??? What typle of quality and performance metrics have been used to evaluate the algorithm. Nasrin: please write a paragraph about this}

The accuracy metric has been used to evaluate the quality of the clustering results and to compare the clustering results from IStrAP and StrAP. The Intrusion Detection benchmark data (KDD99), which distinguishes the attack from normal connections out of labels was used in the evaluation \cite{li2012improved}. The experimental results show that IStrAP can eliminate outliers, and it has shown a higher clustering accuracy than the StrAP algorithm. This approach works well when the data has a normal distribution. %Otherwise, it makes all data points as an outlier if they are out of the standard deviation range.

%and lower time complexity

%IStrAP used KDD Cup 99 dataset and used the Page-Hinkley standard test to update the clustering model. The results show that the IStrAP has higher accuracy, lower time complexity, and better adaptability for stream data over than STRAP. With this dataset, they just chose 120 data points to show the result, and the result is poorly demonstrated with the percent of accuracy and time. FROM WHERE THIS INFORMATION COME FROM???

Another attempt to improve the StrAP algorithm is towards inheriting its advantages but providing a better performance using a dynamic clustering scheme, which ensures that not only new emerging clusters can be detected, but disappeared and recurrent clusters are also timely detected. In the ISTRAP algorithm \cite{sui2018dynamic}, cluster disappearance refers to an existing cluster that is not visited by any recently arrived data points. Cluster re-occurrence occurs when a previously disappeared cluster reoccurs at a later timestamp. 

Outdated clusters are removed and recurrent clusters are efficiently detected rather than being treated as novel clusters. To achieve this, ISTRAP defines the clusters as active and inactive. Active state means that a cluster is still valid at the current timestamp because at least one data point has been assigned to it during the current time interval. Inactive state indicates the clusters is expired since it did not gain any recent data points. Two reservoirs are proposed: an outlier reservoir for saving outliers and the remove reservoir for storing inactive clusters. The workflow of the ISTRAP algorithm is illustrated in Figure \ref{istrap}. The main steps are described as follows:

\begin{figure}[t]
\centering
\includegraphics[width =10 cm]{image/Chapters/Chapter3/istrap1.PNG}
\caption{The proposed ISTRAP clustering workflow}
\label{istrap}
\end{figure}

\begin{itemize}
    \item[$\bullet$] First, initial exemplars are obtained by applying the AP algorithm on the first batch of stream data points.
    \item[$\bullet$] As the stream flows in, each data point goes through the outlier judgment, and the minimum distance of the data point from the exemplar is compared against a threshold. If the distance is less than the threshold, the data point is assigned to the nearest cluster; otherwise, it is sent to the remove reservoir.
    \item[$\bullet$] All clusters in remove reservoir are checked if they re-occur, the recurrent clusters are moved back into the model.
    \item[$\bullet$] The emergence criterion is triggered if new clusters need to be obtained. The model is rebuilt by the WAP algorithm using the data points stored in the outlier reservoir.
    \item[$\bullet$] The model checks all current clusters if they are still active or not. The inactive clusters are removed and sent to the removed reservoir.
\end{itemize}

Four parameters, $\delta$, $\alpha$, $\beta$, $\lambda$, are needed to monitor the clustering process in ISTRAP. The number of outliers is controlled by $\delta$. The emergence threshold for detecting new clusters is defined by $\alpha$, and it affects the stability and processing time of the algorithm. The maximal duration tolerance $\beta$ means an active cluster is not visited by new data points. Larger $\beta$ values mean less possibility that clusters are inactive. The last parameter $\lambda$ represents the minimum number of data points assigned if recurrent clusters have to be sent to the model. If $\lambda$ values are small, it means more recurrent clusters are detected. 

%\todo[inline]{ Nasrin: a paragraph here how this algorithm was tested, labeled or not labeled data, what kind of quaity and performance metrics have used.}

To test the effectiveness of the emergence, disappearance, and recurrent detection of ISTRAP, the AS synthetic and the MNIST real-world data sets were used in the evaluation. The MNIST data set contains images of handwritten digits and their corresponding labels.The results show that ISTRAP and StrAP can detect emergence accuracately; however, the disappearance was not detected by StrAP.

ISTRAP improves the current state of the StrAP model and also the quality of the clusters, but this comes at the cost of introducing additional parameters that have increased the model's complexity and made it not fully automated, which is one of the main goals of a streaming AP algorithm. Moreover, the time complexity have increased compared to the StrAP algorithm due to the computational costs for computing two reservoirs. 

%There is no result available for the time efficiency of this algorithm and compares it with the StrAP model.



% ISTRAP has very powerful effectiveness in tracking the re-occurrence of the with a delay.

\vspace{7mm}
\hspace{-1 cm}
\textbf{APDenStream Algorithm}
%\todo[inline]{Monica: I need to revise this section}

The APDenStream Algorithm is a data stream clustering algorithm based on AP and density methods to improve the StrAP model's accuracy and timeliness in a noisy environment \cite{zhang2013online}. This algorithm employs a two-phase clustering approach, the online and offline phases. The online phase detects data distribution changes due to the new data points, updates the micro-cluster decay density, and generates real-time results. The offline phase, which is invoked by a user who has to choose a specific time frame by applying a pyramidal time window model, gives final query results. 

The clustering process of APDenStream is depicted in Figure \ref{APden}, and it consists of the following steps: 


\begin{figure}[ht]
\centering
\includegraphics[width = 10 cm]{image/Chapters/Chapter3/APDenstream.PNG}
\caption{The APDenStream clustering process}
\label{APden}
\end{figure}


\begin{itemize}
    \item[$\bullet$] AP algorithm is applied to the first $InitN$ points $P$ to initialize the online process. The first group of micro-clusters $mc$ are obtained by scanning $P$. If the micro-cluster density of the micro-cluster $mc$ is greater than the threshold $D$, it is labeled as a dense micro-cluster, and the average radius of all dense micro-clusters is being chosen as an initial radius $\epsilon$.
    
    \item[$\bullet$] As a new data point comes into the model, and it is placed in its nearest dense or sparse micro-cluster. If it is not assigned to any existing micro-cluster, it goes to the reservoir. As time passes, the number of micro-clusters increases. To keep the number of clusters in check and to avoid memory problems, a dynamic online maintenance strategy is used.  First, search for dense micro-clusters in order to determine whether to remove them. Second, search for sparse micro-clusters by checking the minimum weight limit of sparse micro-clusters. 

    \item[$\bullet$] Whenever the reservoir is full, the model is rebuilt, and new clusters are added to the model by applying the WAP algorithm.     
    
   \item[$\bullet$] The last step is offline processing which can master a depth-first traversal to find dense micro-clusters using a snapshot at time $t_c$ and time $t_ch$ can be found in the pyramidal time frames according to the current time $t_c$ and user-specific time range $h$. 
\end{itemize}


For the evaluation of this algorithm, two data sets were used the KDDCUP'99 dataset, and a synthetic Gaussian data. The results show that the APDenStream is more accurate than the StrAP algorithm due to the proposed summary data structure and its online elimination strategy, which maintains the potential micro-clusters in the stream in the time of removal of outlier noise point. Furthermore, APDenStream can remove outliers without having to upgrade potential noise points timely, while in StrAP historical expired micro-clusters are taken into account.


% it is a good paper related to threshod, a metric for data distribution --> old DSAP with 2 threshold

% \item[]\textbf{SSAPStream Algorithm:}

% Atwa and Li \cite{atwa2015affinity} proposed a semi-supervised algorithm, an extended AP called SSAPStream, to handle evolving data streams over the online phase. This method is semi-supervised aims to improve the performance by learning from a combination of both labeled samples and unlabeled data. For a certain labeled data point, $x_i$ and unlabeled data point $x_j$, two possible situations may occur where the labeled data point may be associated with the unlabeled data point after ruining the AP algorithm. One is unlabeled data point $x_j$ takes the labeled point $x_i$ as a cluster centroids, and the other one is the labeled $x_i$ takes the unlabeled $x_j$ as a cluster centroids. If one of these two conditions happens, the unlabeled $x_j$ is the most similar to the label $x_i$. Then, the unlabeled $x_j$ is selected and set to the label of $x_i$. This process will repeat until all unlabeled data points finish.
% They considered that the problem of data stream clustering with the damped time window model then the weight of data points $x_i$, decrease with time $t_k$ and calculated by decay function:

% \begin{equation}
%     w(x_i, t_k) = 2^{\lambda(t_k - t_i)}
% \end{equation}

% The proposed algorithm involves three main steps:
% \begin{itemize}
%     \item[$\bullet$] Apply AP algorithm on the first bunch of data at time $t_0$ to initialize the model.
%     \item[$\bullet$] As a new data point flows into the model, it compares with the existing centroids based on the heuristic threshold; if too far from the nearest centroid, it goes to the buffer, or if it is far, the model will be updated. The threshold $\epsilon$ is set to the average distance between data points and centroids in the initial model.
%     \item[$\bullet$] If a buffer is full or a change in the stream is detected, the model is rebuilt, and buffer 
%     \item[$\bullet$] To prevent the number of centroids goes beyond the control, old ones should be removed. For each centroid, if not any new data point is merged, the weight of the centroid will decay gradually, and it should be deleted.
%     \item[$\bullet$] In order to detect changes in the model, an exemplar variation threshold $\delta$ is introduced to determine if the ratio of data points associated with the centroids is big enough. If the centroid that exceeds $\delta$ is seen as a new cluster centroid. Then, the number of centroids is counted, and the ratio of different these centroids is compared with the new threshold $\phi$. If the ratio of different centroids is larger than the threshold $\phi$, many centroids are varied in the ratio of data items, then the model should be updated.
% \end{itemize}


% To evaluate the effectiveness and efficiency of the algorithm, two real and two synthetic datasets are used. Two real datasets are KDDCUP99 and URLs. KDDCUP99 contains a range of TCP connection records of LAN network traffic. The URLs dataset is used to predict malicious URLs from good ones.
% The SSAPStream algorithm results are compared with the StreamKM++, DenStream, CluStream, and STrap. The output shows that these algorithms have advantages over other algorithms in memory usage except the StreamKM++. 
% To set threshold parameters, they suggested finding the data distribution changes that are not easy for many streaming data. 


% \item[]\textbf{SED-Stream-AP Algorithm:}





% The other stream clustering approach based on the online and offline process is called SED-Stream-AP \cite{sunmood2018evolution}, Based on the evolution-based clustering of SED-Stream, which is able to support the evolution of clustering such as appearance, disappearance, self-evolution, merge and split. The. In the online phase, SED-Stream-AP is able to detect evolving clustering structures, which are cluster appearance, disappearance, self-evolution, merge, and split. During the offline phase, the AP algorithm is adopted to find the final clustering results. The algorithm flowchart is illustrated in Figure \ref{sed}.

% \begin{figure}
% \centering
% \includegraphics[width =10 cm]{image/Chapters/Chapter3/sed.PNG}
% \caption{The framework of SED-Stream-AP algorithm.}
% \label{sed}
% \end{figure}


% The online phase of the SED-Stream-AP algorithm is formed with different steps. First, when a new data point flows into the model, existing clusters in the SED-Stream-AP fade by decay function. Then, based on the splitting and merging features, the algorithm splits and merges the potential clusters if they are needed. Next, if any new cluster appears, it is considered as an active cluster. Lastly, the incoming data point is assigned to the closest cluster.  Otherwise, it creates its 1-element cluster. Specifically, cluster split is based on the distribution of dimension values summarized by the cluster’s histogram.
% If a statistically significant valley is found between two peaks in the histogram’s value along dimensions, the cluster splits. 

% The offline phase operates with the user request and consists of three steps. 
% \begin{itemize}
%     \item[$\bullet$] Retrieves micro-clusters have been obtained from the online phase by using FCH (Fading Cluster Structure with Histogram), a data structure that keeps representations of all the micro-clusters.
%     \item[$\bullet$] Generates new data points only selected dimension from the online phase using cluster representations. The number of data points to be generated is defined based on the weight of the online phase micro-clusters
%     \item[$\bullet$] calculates macro-clusters using the affinity-propagation clustering algorithm.
% \end{itemize}


% The SED-Stream-AP algorithm is evaluated by six different datasets, which are KDDCUP'99, forest covertype, Statlog, breast cancer Wisconsin, electricity, and synthetic datasets. 






%%%%##########  FOR now -- uncomment 
% \section{Data Stream Clustering}

% To perform data stream clustering to access and see the data over the time many data stream clustering algorithm have been introduce.
% CluStream \cite{chen2007density} is online and offline framework for clustering dynamic streaming data. This algorithm uses Pyramidal time window that allow micro-clusters to split and merge over time. Online phase, is sampling process of the $k$ desired clusters and this $k$ clusters are emitted at chosen time intervals, through some off-line clustering method.


% A common baseline algorithm for streaming clustering, is streaming k-Means \cite{ailon2009streaming, braverman2011streaming} uses its update process from the Lloyd algorithm. However, similar to CluStream, micro-clusters is maintained in online phase, to be further clustered in an off-line step. Similar to K-means, streaming K-means has the same process for assigning incoming data points to the nearest representative cluster. The value for having $k$ number of cluster is not available, and this can be done with some sort of inter-cluster similarity or intra-cluster dissimilarity metric. the main drawback of streaming k-Means is that it is highly dependent on the input order of the data stream.
\vspace{7mm}
\hspace{-1 cm}
\textbf{Conclusions}

The differences among the algorithms described above are mainly reflected in the update strategy applied in the processing the data streams (i.e. single-pass or online/offline). Our focus is on designing a novel update strategy for the clustering process, allowing a streaming AP algorithm to handle evolving clusters in a simpler way and thus become more practical. 

Our proposed DSAP algorithm is actually a simplified approach in comparison to IStrAP, ISTRAP, and APDenStream. Our research premise is that indoor localization data streams have a unique time-evolving cluster structure that does not require update strategies such as the WAP algorithm, outlier repository, decay function, and reocurrence judgement rules to handle outliers. 

Mainly because the constrained indoor spaces where the data streams are collected make the occurrence of outliers extremely low. This is usually not the case in social media networks such as Twitter, where timely topics appear quickly (cluster emergence) while older topics lose relevance over time (cluster disappearance). To the best of our knowledge, StrAP, IsrAP, ISTRAP, and APDenStream have not yet been applied for indoor localization data streams. Unfortunately, the programming codes of these algorithms were not provided by their authors to us, hampering their evaluation in terms of finding streaming clusters from indoor localization data.

Moreover, DSAP aims to handle the flow of stream data points by proposing the landmark time window model for the online phase of the clustering process. Out of the previously proposed algorithms, none of them have explored the landmark time window before. Mainly because StrAP, IsrAP, ISTRAP, and APDenStream take the opportunity to use a repository to emulate the sliding time window model in the single-pass/online phase. 

The landmark time window model separates the stream data points based on a landmark time interval (e.g. every minute) or by a landmark event (e.g. people are not detected in an indoor space), when after a landmark is reached, new data points start to be captured in a separate window. This strategy is particularly advantageous for defining temporal relationships among arriving data points since it creates a meaningful sequence of time order snapshots. Once a set of new data points has been gathered for one active time window, the evolution of cluster relationships over time can be generated. 

Furthermore, the DSAP algorithm allows the user to decide to keep a number of landmark time window models active in order to avoid removing historical clusters, and ensure that historical discovered clusters are equally important in the clustering process. Basically the number of active time windows dictates how much data will be used continuously for detecting new clusters. To the best of our knowledge, this type of strategy has not been previously proposed in the literature.

% \todo[inline]{repository story here do we have repository  "time-window based repository" so we do not need the reoccurence, emergence, etc.. write the advanatges of this approach

% also missing: expiration parameter alph, beta, parameter to tune the updating, we can use only one the expirations???  treshold is usualy the mean, but in our case we update the treshold} 


Finally, the proposed DSAP algorithm avoids the computation to detect the emergence, re-occurrence, and disappearance of clusters in order to avoid adding any additional costs. It introduces the concept of time windows and dynamic threshold for the first time for an affinity propagation-based stream clustering algorithm. Every window can detect the emergence of new clusters while clusters older than the expiration time are removed. Unlike some of the other algorithms that require tuning several parameters to capture the current state of the model, DSAP uses a simple combination of autonomously calculated dynamic threshold and expiration time to keep the algorithm more efficient.

%Moreover, updating the threshold value in each window makes the DSAP algorithm more robust and improves the quality of clusters. 


 


% %any streaming algo for indoor
% ###################

% \todo[inline]{research premise + conclusions

%  As far as we had research, there is not any research work present with affinity propagation used landmark time window model.

% is there  any paper related to occupant behaviour(stair usage) + stream clustering???
% There is no paper related to ecounter(sensors) + clustering as well as stream clustering????

% paper related to people counter+ clustering ????

% Several data stream clustering algorithms have been implemented with the AP algorithm using different time window models. Out of all these algorithms, none of them implemented with a landmark time window model. Moreover, all these algorithms tested on synthetic and intrusion detection algorithms. There are few works that applied the AP algorithm on indoor localization data. _>> to be used for conclusions
% Type of algorithm  
% Data Type Labeled Data
% Criteria density
% Evaluation Metrics   


% why we havent used this algorithm: our data is already densed 

% all of them used weighted WAP: why havent we used WAP???
% one of the reasons for us not to use stattics and WAP was that our data is inherently do do contain outliers}

% \section{occupancy}
%\section{Latest Development in Indoor Localization }

% PAPER'S BELOW SHOULD BE MOVED TO THE PREVIOUS METHODS


% The people’s counting is a very important topic to design any system for behavioral analysis. It is used to measure and manage people’s behaviour within area.

% Using stairs and monitor human activity in the building is one scenario for indoor localization and behaviour analysis.


% %Carbonare et al. \cite{carbonare2018clustering} uses clustering method to investigate the occupant behaviour and their pattern in residential buildings. Two clustering method have been used: Whole time series and feature clustering with the K-means and these features are window opening and indoor temperature. The results show that feature selection has a better output than time series clustering. ?????
   


% %There are many works dealing with the indoor localization problem by using WLAN-based techniques.
% Clustering method could efficiently reduce computational complexity and memory requirements in large fingerprinting localization data to train ANN model. K-means clustering algorithm is one of these algorithm which is easy to implement with low time complexity. However, this algorithm is starts with an initial guess as a number of clusters, which is in the condition of close to the true solution to avoid local minima. Selection of such a starting point is not easy. Also, it would affect the location accuracy performance \cite{das2007automatic, ding2013fingerprinting}.

% Genming et al. \cite{ding2013fingerprinting} introduces a fingerprinting-based localization algorithm using affinity propagation in conjunction with neural network. 
% This model consists of two stage offline and online. The offline stage applies clustering and ANN training on the data. First,  a set of RSS from N available access point is collected and stored in the database. AP clustering algorithm is used in this part to to reduce the computation cost and memory of the system and partitions the reference points into different clusters represents by centroids. After clustering, the training of artificial neural network is carried out for each cluster.
% The online stage, the unknown location is obtained by in two steps. First, by applying pattern matching to calculate the similarity between the new collected signal and cluster centroids and then choose sets of best match clusters for the next ANN localization phase.

% Xuke et al. \cite{hu2015improving} proposes an improved WiFi fingerprinting positioning algorithm called WKNN-SAP. First, a new fingerprint distance estimation using RSS distances and access points similarities is used. Then, semi-supervised AP clustering algorithm is applied to find isolated points and remove them to have a reasonable clustering output and eliminate some outliers.

% On the other hand, they applied K-means algorithm to compared both clustering results to improve the localization accuracy. and they figured out that while AP outperforms Kmeans in both the accuracy improvement and stability and this is because AP algorithm is less affected by the clustering number. Moreover, proposed fingerprint distance model can better adapt to the indoor environment with distinct access points.

% %Existing stream clustering algorithms often have issues regarding asymptotic scalability [3], dimensionality limits [4] and robustness to noise





% Lee et al. \cite{carraher2016random} introduces streamingRPHash is motivated by
% a particularly difficult case in Nearest Neighbor, a method for clustering high-dimensional data streams to solve the other clustering problem on streaming data by applying two real world dataset, ujIIndoorLoc and ‘Human Activity Recognition datasets.
% For UjIIndoorLoc data, based on the 520 of signal strength intensity, building ID is used as the target variable which has three possible values related to each building.
% Human Activity Recognition datasets has 561 attributes representing time and frequency domain variables.
% the result of the proposed algorithm is compared with the streaming K-means, and DSt algorithms and it shows that their proposed algorithm and streaming K-means have the same results in term of run-time and memory requirement but with increase the dimension, streamingRPHash has a better result.


%K-means algorithm is one of the most common methods for clustering distance-based objects that we have applied for our data. However, this method is less effective, or even inapplicable, for the application we used. For example, K-means results find cluster centroids between locations which does not make sense for our interpretation. 


%  affinity propagation can be used to cluster objects measured on non‐distance‐based similarity measures that arise in psychology, such as those obtained from stimulus recognition or paired comparison tasks (see, for example, Hubert, Arabie, & Meulman,

% #######LR CONCLUSIONS

% It is important to point out that none of them have been implemented using the landmark time window model. Moreover, all these algorithms were tested on synthetic and intrusion detection data streams. To the best of our knowledge, no previous research work was found in applying streaming AP for finding patterns from indoor localization data streams.

% \todo[inline]{STRAP,  ISTRAP but just with a new method to deal with outliers, 

% the chances of having an outlier are very low, and we woul dnt need to compute statistics, we could easily detect outliers using distance functions )proximity metrics

% DSAP is actually a simplification approach in comparison to STRAP and ISTRAP

% need to know what type of data they have used for the benchmarking : label or not labeled data

% they can only be used with sliding windows, because the repository emulates the sliding time window model

% ##########
% WAP: wwhy can not find a justification for not applying a decay function??? or weights or anything to handle historical data points

% No decay function (computational cost) is used here for eliminating historical centroids which are longer relevant to the clustering process. we have used the expiration parameter = total number of timw widows used in the computation of micro-clusters over time.. basically dicates how much data will be contiuoulsy being used for the clustering

% ##########


% In order to avoid the number of centroids to spread beyond control (volume), 

% old centroids that are no longer deemed relevant are removed. (history)

% No decay function is used here for eliminating historical centroids wich ar enot longer relevant to the clustering process.
% To do this, 

% an expiration parameter $e_x$ is actually the number of time windows that are used for computing the micro-clusters which is defined by the user.

% introduced. 

% This value is applied to forget centroids that haven't been selected in the recent windows as quantified by $ex$. The $ex$ number can be chosen to include all the time windows from the start or just the last few windows, depending on the user requirements. All the clusters whose associated timestamps are older than $ex$ window lengths ($ex \times L$) from the current time are considered obsolete and hence discarded. }

% \end{document}